{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhWhpAdZKC_W"
      },
      "source": [
        "# napari-mAIcrobe cell cycle model training\n",
        "---\n",
        "napari-mAIcrobe, is a napari based re-implementation of eHooke. eHooke was developed as an image analysis framework developed specifically for automated analysis of microscopy images of spherical bacterial cells. The original eHooke contained a trained artificial neural network to automatically classify the cell cycle phase of individual *S. aureus* cells.\n",
        "\n",
        "In this notebook we enable training of the original eHooke neural network for an arbitrary number of channels and classes.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v18WxQIyqZg0"
      },
      "source": [
        "## Before getting started\n",
        "\n",
        "-   Make sure you have the training and test data already loaded into your Google Drive.\n",
        "\n",
        "-   Preprocess your data into the correct format - use the generate_pickles widget in napari-mAIcrobe to do this.\n",
        "\n",
        "-   Currently the input to the model is given by two folders that can contain multiple pickle (.p) files which form a pair - the training source and the training target.\n",
        "-   The training source is a pickled python list of numpy arrays where each array is a 100x(#channels*100)\n",
        "\n",
        "-   The training target is a list of integer labels that correspond to the cell cycle phase.\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lWKDfzqJQ2iX",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title 1. Install all depencencies\n",
        "!pip uninstall -qy fastai albucore spacy albumentations grpcio-status jax flax optax chex dopamine-rl tensorflow-text tensorflow-decision-forests keras-hub orbax-checkpoint tensorstore opencv-python-headless opencv-python opencv-contrib-python ydf thinc\n",
        "!pip install -q tensorflow==2.15.0 keras==2.15.0 numpy==1.26.4 tf-keras==2.15 grpcio==1.71.0\n",
        "exit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "_x6w7fkzLiYK"
      },
      "outputs": [],
      "source": [
        "#@title 2. Import necessary libraries and connect to Google Drive\n",
        "\n",
        "import sys\n",
        "import os\n",
        "\n",
        "import math\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Input\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, Flatten, RandomFlip, RandomRotation\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "from glob import glob\n",
        "from tifffile import imread\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import pickle\n",
        "\n",
        "class CellCycleSequence(tf.keras.utils.Sequence):\n",
        "\n",
        "    def __init__(self, x_set, y_set, batch_size, n_channels):\n",
        "        super().__init__()\n",
        "        self.x, self.y = x_set, y_set\n",
        "        self.batch_size = batch_size\n",
        "        self.n_channels = n_channels\n",
        "\n",
        "    def __len__(self):\n",
        "        return math.ceil(len(self.y) / self.batch_size)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        batch_x = self.x[idx*self.batch_size: (idx + 1)*self.batch_size]\n",
        "        batch_y = self.y[idx*self.batch_size: (idx + 1)*self.batch_size]\n",
        "\n",
        "        return np.array(batch_x).reshape(-1,100,self.n_channels*100,1), np.array(batch_y)\n",
        "\n",
        "\n",
        "class ModelTrainer:\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        self.X_trn = None\n",
        "        self.y_trn = None\n",
        "\n",
        "        self.X_val = None\n",
        "        self.y_val = None\n",
        "\n",
        "        self.trn_sequence = None\n",
        "        self.val_sequence = None\n",
        "\n",
        "    def load_data(self, X_path, y_path, val_split, nchannels):\n",
        "\n",
        "        # get all pickles in the X_path folder\n",
        "        X_files = glob(os.path.join(X_path, \"*.p\"))\n",
        "        y_files = glob(os.path.join(y_path, \"*.p\"))\n",
        "        assert len(X_files) == len(y_files), \"Number of X and y pickle files must be the same\"\n",
        "        print(f\"Found {len(X_files)} pickle files in {X_path} and {y_path}\")\n",
        "        # load all pickles and concatenate them\n",
        "        X = []\n",
        "        y = []\n",
        "        for xf, yf in zip(sorted(X_files), sorted(y_files)):\n",
        "            print(f\"Loading {xf} and {yf}\")\n",
        "            with open(xf, 'rb') as xfile:\n",
        "                X_part = pickle.load(xfile)\n",
        "                X.extend(X_part)\n",
        "            with open(yf, 'rb') as yfile:\n",
        "                y_part = pickle.load(yfile)\n",
        "                y.extend(y_part)\n",
        "        X = np.array(X)\n",
        "        y = np.array(y)\n",
        "        print(f\"Loaded {len(X)} samples\")\n",
        "        y = [int(i)-1 for i in y]\n",
        "\n",
        "        rng = np.random.RandomState()\n",
        "        ind = rng.permutation(len(y))\n",
        "        n_val = max(1, int(round(val_split * len(ind))))\n",
        "        ind_train, ind_val = ind[:-n_val], ind[-n_val:]\n",
        "        self.X_val, self.Y_val = [X[i] for i in ind_val]  , [y[i] for i in ind_val]\n",
        "        self.X_trn, self.Y_trn = [X[i] for i in ind_train], [y[i] for i in ind_train]\n",
        "        print('number of images: %3d' % len(X))\n",
        "        print('- training:       %3d' % len(self.X_trn))\n",
        "        print('- validation:     %3d' % len(self.X_val))\n",
        "\n",
        "        sample_inds = rng.randint(0,len(y),size=3)\n",
        "        fig = plt.figure(figsize=(5,9))\n",
        "        subfigs = fig.subfigures(nrows=3,ncols=1)\n",
        "        for row,subfig in enumerate(subfigs):\n",
        "            sind = sample_inds[row]\n",
        "            subfig.suptitle(f\"Phase # {y[sind]+1}\")\n",
        "\n",
        "            axs = subfig.subplots(nrows=1,ncols=nchannels)\n",
        "            for nc in range(nchannels):\n",
        "                if nchannels==1:\n",
        "                    axs.imshow(X[sind][:,0:100],cmap='gray',clim=(0,1))\n",
        "                    axs.set_title(f\"Channel # {nc}\")\n",
        "                else:\n",
        "                    axs[nc].imshow(X[sind][:,0+nc*100:100+nc*100],cmap='gray',clim=(0,1))\n",
        "                    axs[nc].set_title(f\"Channel # {nc}\")\n",
        "\n",
        "    def create_model(self, depth, cellcyclephases, n_channels, augbool = False, hflip=False, vflip=False, rotfactor=0):\n",
        "        self.model = Sequential()\n",
        "\n",
        "        self.model.add(Input(shape=(100,n_channels*100,1)))\n",
        "\n",
        "        if augbool:\n",
        "            if hflip and vflip:\n",
        "                self.model.add(RandomFlip(mode='horizontal_and_vertical'))\n",
        "            elif hflip:\n",
        "                self.model.add(RandomFlip(mode='horizontal'))\n",
        "            elif vflip:\n",
        "                self.model.add(RandomFlip(mode='vertical'))\n",
        "\n",
        "            if rotfactor>0:\n",
        "                self.model.add(RandomRotation(rotfactor))\n",
        "\n",
        "        self.model.add(Conv2D(16, (3, 3), padding='same'))\n",
        "        self.model.add(Activation('relu'))\n",
        "\n",
        "        if depth > 1:\n",
        "            self.model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "            if depth > 2:\n",
        "                self.model.add(Conv2D(16, (3, 3), padding='same'))\n",
        "                self.model.add(Activation('relu'))\n",
        "\n",
        "                if depth > 3:\n",
        "                    self.model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "                    if depth > 4:\n",
        "                        self.model.add(Conv2D(16, (3, 3), padding='same'))\n",
        "                        self.model.add(Activation('relu'))\n",
        "\n",
        "                        if depth > 5:\n",
        "                            self.model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "                            if depth > 6:\n",
        "                                self.model.add(Conv2D(32, (3, 3), padding='same'))\n",
        "                                self.model.add(Activation('relu'))\n",
        "\n",
        "                                if depth > 7:\n",
        "                                    self.model.add(Conv2D(32, (3, 3), padding='same'))\n",
        "                                    self.model.add(Activation('relu'))\n",
        "\n",
        "                                    if depth > 8:\n",
        "                                        self.model.add(Conv2D(32, (3, 3), padding='same'))\n",
        "                                        self.model.add(Activation('relu'))\n",
        "\n",
        "                                        if depth > 9:\n",
        "                                            self.model.add(Conv2D(32, (3, 3), padding='same'))\n",
        "                                            self.model.add(Activation('relu'))\n",
        "\n",
        "                                            if depth > 10:\n",
        "                                                self.model.add(Flatten())\n",
        "                                                self.model.add(Dense(100))\n",
        "                                                self.model.add(Activation('relu'))\n",
        "        if depth <= 10:\n",
        "            self.model.add(Flatten())\n",
        "            pass\n",
        "\n",
        "        self.model.add(Dense(cellcyclephases))\n",
        "        self.model.add(Activation('softmax'))\n",
        "        #self.model.summary()\n",
        "\n",
        "\n",
        "    def compile_model(self,learningrate):\n",
        "        self.model.compile(loss='sparse_categorical_crossentropy',\n",
        "                           optimizer=tf.keras.optimizers.Adam(learningrate),\n",
        "                           metrics=['accuracy'])\n",
        "\n",
        "    def train_model(self, model_path, n_epochs, n_batch_size, n_channels):\n",
        "        #tbCallBack = TensorBoard(log_dir=\"Graph\", histogram_freq=0, write_graph=True, write_images=True)\n",
        "        checkpoint = ModelCheckpoint(os.path.join(model_path,\"weights_{epoch}.keras\"), verbose=1, monitor=\"val_loss\", save_best_only=True)\n",
        "        #earlystopper = EarlyStopping(patience=50, monitor=\"val_loss\", mode=\"auto\", verbose=1)\n",
        "\n",
        "        history = self.model.fit(x=CellCycleSequence(self.X_trn, self.Y_trn, n_batch_size, n_channels),\n",
        "                                 validation_data = CellCycleSequence(self.X_val, self.Y_val, n_batch_size, n_channels),\n",
        "                                 epochs=n_epochs, verbose=1,\n",
        "                                 callbacks=[checkpoint])\n",
        "\n",
        "        return history\n",
        "\n",
        "    def save_model(self,model_path):\n",
        "        self.model.save(os.path.join(model_path,\"weights_last.keras\"))\n",
        "\n",
        "model_trainer = ModelTrainer()\n",
        "\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "if IN_COLAB:\n",
        "    from google.colab import output\n",
        "    output.enable_custom_widget_manager()\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "BryrmtkQyOHL"
      },
      "outputs": [],
      "source": [
        "#@title 3. Load data and select training parameters\n",
        "\n",
        "#@markdown ###Load data:\n",
        "Training_source = '' #@param {type:\"string\"}\n",
        "Training_target = '' #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ###Model parameters:\n",
        "n_cell_cycle_stages = 3#@param {type:\"integer\"}\n",
        "n_channels = 2#@param {type:\"integer\"}\n",
        "depth = 11#@param {type:\"integer\"}\n",
        "\n",
        "#@markdown ###Training parameters:\n",
        "number_of_epochs =  200#@param {type:\"integer\"}\n",
        "batch_size =  32#@param {type:\"integer\"}\n",
        "percentage_validation =  0.2#@param{type:\"number\"}\n",
        "initial_learning_rate = 0.001 #@param {type:\"number\"}\n",
        "\n",
        "#@markdown #### Data augmentation\n",
        "\n",
        "dataaugmentation = True #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown Rotation\n",
        "factor_rotations =  0.5 #@param {type:\"slider\", min:0, max:1, step:0.05}\n",
        "\n",
        "#@markdown Flips\n",
        "horizontal_flip = True #@param {type:\"boolean\"}\n",
        "vertical_flip = True #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "#@markdown ###Save model:\n",
        "model_path = '' #@param {type:\"string\"}\n",
        "\n",
        "if not os.path.exists(model_path):\n",
        "    os.mkdir(model_path)\n",
        "\n",
        "\n",
        "model_trainer.load_data(X_path=Training_source,y_path=Training_target,val_split=percentage_validation,nchannels=n_channels)\n",
        "\n",
        "model_trainer.create_model(depth,n_cell_cycle_stages,n_channels,augbool = dataaugmentation, hflip=horizontal_flip, vflip=vertical_flip, rotfactor=factor_rotations)\n",
        "\n",
        "model_trainer.compile_model(initial_learning_rate)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "p_9fKPWeLFn-"
      },
      "outputs": [],
      "source": [
        "#@title 4. Start model training (Warning: this might take a long time)\n",
        "\n",
        "\n",
        "model_history = model_trainer.train_model(model_path,number_of_epochs,batch_size,n_channels)\n",
        "model_trainer.save_model(model_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "aBWZfqjELhTa"
      },
      "outputs": [],
      "source": [
        "#@title 5. Assess Quality Control\n",
        "\n",
        "#@markdown ###Load data:\n",
        "QC_source = '' #@param {type:\"string\"}\n",
        "QC_target = '' #@param {type:\"string\"}\n",
        "\n",
        "tX = np.array(pickle.load(open(QC_source, \"rb\")))\n",
        "tX = np.array(tX).reshape(-1,100,n_channels*100,1)\n",
        "ty = np.array(pickle.load(open(QC_target, \"rb\")))\n",
        "\n",
        "predicted = np.argmax(model_trainer.model.predict(tX),axis=1)+1\n",
        "\n",
        "model_metrics = model_history.history\n",
        "fig,axs = plt.subplots(1,2)\n",
        "\n",
        "axs[0].plot(model_metrics['loss'],label='loss')\n",
        "axs[0].plot(model_metrics['val_loss'],label='val_loss')\n",
        "axs[0].legend()\n",
        "axs[0].set_xlabel('Epoch')\n",
        "axs[0].set_ylabel('loss')\n",
        "\n",
        "axs[1].plot(model_metrics['accuracy'],label='accuracy')\n",
        "axs[1].plot(model_metrics['val_accuracy'],label='val_accuracy')\n",
        "axs[1].legend()\n",
        "axs[1].set_xlabel('Epoch')\n",
        "axs[1].set_ylabel('accuracy')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "conf = confusion_matrix(ty,predicted)\n",
        "confaxs = ConfusionMatrixDisplay(confusion_matrix=conf, display_labels=(1,2,3))\n",
        "confaxs.plot()\n",
        "plt.title(\"Confusion matrix\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "naparimaicrobedev",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}